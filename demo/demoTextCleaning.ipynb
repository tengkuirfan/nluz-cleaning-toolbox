{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab3f4381",
   "metadata": {},
   "source": [
    "# Text Cleaning Toolbox Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c1f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports successful!\n",
      "ðŸ“¦ TextCleaning module loaded\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nluztoolbox import TextCleaning, get_contractions_dict, download_nltk_data\n",
    "\n",
    "print(\"âœ… Imports successful!\")\n",
    "print(\"ðŸ“¦ TextCleaning module loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32cea06",
   "metadata": {},
   "source": [
    "## Part 1: Single Text String Examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ba658a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original text:\n",
      "\"  Hello WORLD! I can't believe it's 2024. Visit https://example.com or email test@example.com. <p>HTML tags here</p>  \"\n"
     ]
    }
   ],
   "source": [
    "# Sample text with various issues\n",
    "sample_text = \"  Hello WORLD! I can't believe it's 2024. Visit https://example.com or email test@example.com. <p>HTML tags here</p>  \"\n",
    "print(f\"\\nOriginal text:\\n{repr(sample_text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5ea94d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 1: Lowercase ---\n",
      "Result: \"  hello world! i can't believe it's 2024. visit https://example.com or email test@example.com. <p>html tags here</p>  \"\n",
      "\n",
      "--- Example 2: Uppercase ---\n",
      "Result: \"  HELLO WORLD! I CAN'T BELIEVE IT'S 2024. VISIT HTTPS://EXAMPLE.COM OR EMAIL TEST@EXAMPLE.COM. <P>HTML TAGS HERE</P>  \"\n",
      "\n",
      "--- Example 3: Remove Punctuation ---\n",
      "Result: '  Hello WORLD I cant believe its 2024 Visit httpsexamplecom or email testexamplecom pHTML tags herep  '\n",
      "\n",
      "--- Example 4: Remove Punctuation (Keep some) ---\n",
      "Result: '  Hello WORLD! I cant believe its 2024. Visit httpsexample.com or email testexample.com. pHTML tags herep  '\n",
      "\n",
      "--- Example 5: Expand Contractions ---\n",
      "Result: '  Hello WORLD! I cannot believe it is 2024. Visit https://example.com or email test@example.com. <p>HTML tags here</p>  '\n",
      "\n",
      "--- Example 6: Remove URLs and Emails ---\n",
      "Result: \"  Hello WORLD! I can't believe it's 2024. Visit  or email . <p>HTML tags here</p>  \"\n",
      "\n",
      "--- Example 7: Remove HTML Tags ---\n",
      "Result: \"  Hello WORLD! I can't believe it's 2024. Visit https://example.com or email test@example.com. HTML tags here  \"\n",
      "\n",
      "--- Example 8: Remove Extra Whitespace ---\n",
      "Result: \"Hello WORLD! I can't believe it's 2024. Visit https://example.com or email test@example.com. <p>HTML tags here</p>\"\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Lowercase conversion\n",
    "print(\"\\n--- Example 1: Lowercase ---\")\n",
    "result = TextCleaning(sample_text).lowercase().get()\n",
    "print(f\"Result: {repr(result)}\")\n",
    "\n",
    "# Example 2: Uppercase conversion\n",
    "print(\"\\n--- Example 2: Uppercase ---\")\n",
    "result = TextCleaning(sample_text).uppercase().get()\n",
    "print(f\"Result: {repr(result)}\")\n",
    "\n",
    "# Example 3: Remove punctuation\n",
    "print(\"\\n--- Example 3: Remove Punctuation ---\")\n",
    "result = TextCleaning(sample_text).remove_punctuation().get()\n",
    "print(f\"Result: {repr(result)}\")\n",
    "\n",
    "# Example 4: Remove punctuation but keep some\n",
    "print(\"\\n--- Example 4: Remove Punctuation (Keep some) ---\")\n",
    "result = TextCleaning(sample_text).remove_punctuation(keep=\".,!?\").get()\n",
    "print(f\"Result: {repr(result)}\")\n",
    "\n",
    "# Example 5: Expand contractions\n",
    "print(\"\\n--- Example 5: Expand Contractions ---\")\n",
    "result = TextCleaning(sample_text).expand_contractions().get()\n",
    "print(f\"Result: {repr(result)}\")\n",
    "\n",
    "# Example 6: Remove URLs and emails\n",
    "print(\"\\n--- Example 6: Remove URLs and Emails ---\")\n",
    "result = TextCleaning(sample_text).remove_urls().remove_emails().get()\n",
    "print(f\"Result: {repr(result)}\")\n",
    "\n",
    "# Example 7: Remove HTML tags\n",
    "print(\"\\n--- Example 7: Remove HTML Tags ---\")\n",
    "result = TextCleaning(sample_text).remove_html_tags().get()\n",
    "print(f\"Result: {repr(result)}\")\n",
    "\n",
    "# Example 8: Remove extra whitespace\n",
    "print(\"\\n--- Example 8: Remove Extra Whitespace ---\")\n",
    "result = TextCleaning(sample_text).remove_whitespace(mode=\"extra\").get()\n",
    "print(f\"Result: {repr(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be33f4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 9: Chaining Multiple Operations ---\n",
      "Result: 'hello world i cannot believe it is 2024 visit or email html tags here'\n"
     ]
    }
   ],
   "source": [
    "# Example 9: Chaining multiple operations\n",
    "print(\"\\n--- Example 9: Chaining Multiple Operations ---\")\n",
    "result = (TextCleaning(sample_text)\n",
    "          .lowercase()\n",
    "          .expand_contractions()\n",
    "          .remove_urls()\n",
    "          .remove_emails()\n",
    "          .remove_html_tags()\n",
    "          .remove_punctuation()\n",
    "          .remove_whitespace(mode=\"extra\")\n",
    "          .get())\n",
    "print(f\"Result: {repr(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62bde64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 10: Split Text ---\n",
      "Result: ['apple', 'banana', 'orange', 'grape']\n",
      "\n",
      "--- Example 11: Simple Tokenization ---\n",
      "Result: ['This', 'is', 'a', 'simple', 'sentence', 'for', 'tokenization']\n"
     ]
    }
   ],
   "source": [
    "# Example 10: Split text\n",
    "print(\"\\n--- Example 10: Split Text ---\")\n",
    "text = \"apple,banana,orange,grape\"\n",
    "result = TextCleaning(text).split_text(delimiter=',')\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "# Example 11: Simple tokenization (no NLTK required)\n",
    "print(\"\\n--- Example 11: Simple Tokenization ---\")\n",
    "text = \"This is a simple sentence for tokenization\"\n",
    "result = TextCleaning(text).tokenize(method=\"simple\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315be29c",
   "metadata": {},
   "source": [
    "## Part 2: Dataframe Column Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd1d0819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't believe it's working!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Visit https://example.com for more INFO.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extra   spaces   everywhere</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remove &lt;b&gt;HTML&lt;/b&gt; tags and email@test.com</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DON'T SHOUT AT ME!!!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text  id\n",
       "0               I can't believe it's working!   1\n",
       "1    Visit https://example.com for more INFO.   2\n",
       "2               Extra   spaces   everywhere     3\n",
       "3  Remove <b>HTML</b> tags and email@test.com   4\n",
       "4                        DON'T SHOUT AT ME!!!   5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'text': [\n",
    "        \"I can't believe it's working!\",\n",
    "        \"Visit https://example.com for more INFO.\",\n",
    "        \"  Extra   spaces   everywhere  \",\n",
    "        \"Remove <b>HTML</b> tags and email@test.com\",\n",
    "        \"DON'T SHOUT AT ME!!!\"\n",
    "    ],\n",
    "    'id': [1, 2, 3, 4, 5]\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a577a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 12: Lowercase on DataFrame ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>text_lowercase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't believe it's working!</td>\n",
       "      <td>1</td>\n",
       "      <td>i can't believe it's working!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Visit https://example.com for more INFO.</td>\n",
       "      <td>2</td>\n",
       "      <td>visit https://example.com for more info.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extra   spaces   everywhere</td>\n",
       "      <td>3</td>\n",
       "      <td>extra   spaces   everywhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remove &lt;b&gt;HTML&lt;/b&gt; tags and email@test.com</td>\n",
       "      <td>4</td>\n",
       "      <td>remove &lt;b&gt;html&lt;/b&gt; tags and email@test.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DON'T SHOUT AT ME!!!</td>\n",
       "      <td>5</td>\n",
       "      <td>don't shout at me!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text  id  \\\n",
       "0               I can't believe it's working!   1   \n",
       "1    Visit https://example.com for more INFO.   2   \n",
       "2               Extra   spaces   everywhere     3   \n",
       "3  Remove <b>HTML</b> tags and email@test.com   4   \n",
       "4                        DON'T SHOUT AT ME!!!   5   \n",
       "\n",
       "                               text_lowercase  \n",
       "0               i can't believe it's working!  \n",
       "1    visit https://example.com for more info.  \n",
       "2               extra   spaces   everywhere    \n",
       "3  remove <b>html</b> tags and email@test.com  \n",
       "4                        don't shout at me!!!  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 12: Lowercase on DataFrame column\n",
    "print(\"\\n--- Example 12: Lowercase on DataFrame ---\")\n",
    "df['text_lowercase'] = TextCleaning(df, text_column='text').lowercase().get()['text']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47206ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 13: Multiple Operations on DataFrame ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>text_lowercase</th>\n",
       "      <th>text_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't believe it's working!</td>\n",
       "      <td>1</td>\n",
       "      <td>i can't believe it's working!</td>\n",
       "      <td>i cannot believe it is working</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Visit https://example.com for more INFO.</td>\n",
       "      <td>2</td>\n",
       "      <td>visit https://example.com for more info.</td>\n",
       "      <td>visit for more info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extra   spaces   everywhere</td>\n",
       "      <td>3</td>\n",
       "      <td>extra   spaces   everywhere</td>\n",
       "      <td>extra spaces everywhere</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Remove &lt;b&gt;HTML&lt;/b&gt; tags and email@test.com</td>\n",
       "      <td>4</td>\n",
       "      <td>remove &lt;b&gt;html&lt;/b&gt; tags and email@test.com</td>\n",
       "      <td>remove html tags and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DON'T SHOUT AT ME!!!</td>\n",
       "      <td>5</td>\n",
       "      <td>don't shout at me!!!</td>\n",
       "      <td>do not shout at me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         text  id  \\\n",
       "0               I can't believe it's working!   1   \n",
       "1    Visit https://example.com for more INFO.   2   \n",
       "2               Extra   spaces   everywhere     3   \n",
       "3  Remove <b>HTML</b> tags and email@test.com   4   \n",
       "4                        DON'T SHOUT AT ME!!!   5   \n",
       "\n",
       "                               text_lowercase                    text_cleaned  \n",
       "0               i can't believe it's working!  i cannot believe it is working  \n",
       "1    visit https://example.com for more info.             visit for more info  \n",
       "2               extra   spaces   everywhere           extra spaces everywhere  \n",
       "3  remove <b>html</b> tags and email@test.com            remove html tags and  \n",
       "4                        don't shout at me!!!              do not shout at me  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 13: Multiple operations on DataFrame\n",
    "print(\"\\n--- Example 13: Multiple Operations on DataFrame ---\")\n",
    "df['text_cleaned'] = (TextCleaning(df, text_column='text')\n",
    "                      .lowercase()\n",
    "                      .expand_contractions()\n",
    "                      .remove_urls()\n",
    "                      .remove_emails()\n",
    "                      .remove_html_tags()\n",
    "                      .remove_punctuation()\n",
    "                      .remove_whitespace(mode=\"extra\")\n",
    "                      .get()['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f25055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 14: Custom Function Processing ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    I have [NUM] apples and [NUM] oranges\n",
       "1             Call me at [NUM]-[NUM]-[NUM]\n",
       "2                                      NaN\n",
       "3                                      NaN\n",
       "4                                      NaN\n",
       "Name: text_function, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 14: Custom function processing\n",
    "print(\"\\n--- Example 14: Custom Function Processing ---\")\n",
    "def custom_cleanup(text):\n",
    "    return re.sub(r'\\d+', '[NUM]', text)\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    'text': [\"I have 5 apples and 10 oranges\", \"Call me at 123-456-7890\"]\n",
    "})\n",
    "df['text_function'] = TextCleaning(df_test, text_column='text').process_text(custom_cleanup).get()\n",
    "df['text_function']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5094b1",
   "metadata": {},
   "source": [
    "## Part 3: NLTK-Based Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5f1725c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NOTE: These examples require NLTK data to be downloaded.\n",
      "If you get errors, run: download_nltk_data()\n",
      "Or manually: import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet')\n",
      "\n",
      "--- Example 15: Word Tokenization (NLTK) ---\n",
      "Result: ['Hello', '!', 'How', 'are', 'you', 'doing', 'today', '?', 'I', \"'m\", 'doing', 'great', '.']\n",
      "\n",
      "--- Example 16: Sentence Tokenization ---\n",
      "Result: ['Hello!', 'How are you?', \"I'm doing great.\", 'What about you?']\n",
      "\n",
      "--- Example 17: Remove Stopwords (English) ---\n",
      "Result: sample sentence common words\n",
      "\n",
      "--- Example 18: Porter Stemming ---\n",
      "Result: run run runner ran easili fairli\n",
      "\n",
      "--- Example 19: Snowball Stemming ---\n",
      "Result: run run runner ran easili fair\n",
      "\n",
      "--- Example 20: Lemmatization (Noun) ---\n",
      "Result: running run runner ran easily fairly\n",
      "\n",
      "--- Example 21: Lemmatization (Verb) ---\n",
      "Result: run run runner run\n",
      "\n",
      "--- Example 22: Complete NLP Pipeline ---\n",
      "\n",
      "Original DataFrame:\n",
      "                                       text\n",
      "0   I'm running quickly through the forest!\n",
      "1    The cats were playing with their toys.\n",
      "2  She doesn't like swimming in cold water.\n",
      "\n",
      "Cleaned DataFrame (with stemming):\n",
      "                   text\n",
      "0    run quickli forest\n",
      "1          cat play toy\n",
      "2  like swim cold water\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import nltk\n",
    "    \n",
    "    print(\"\\nNOTE: These examples require NLTK data to be downloaded.\")\n",
    "    print(\"If you get errors, run: download_nltk_data()\")\n",
    "    print(\"Or manually: import nltk; nltk.download('punkt'); nltk.download('stopwords'); nltk.download('wordnet')\")\n",
    "    \n",
    "    # Example 15: Word tokenization with NLTK\n",
    "    print(\"\\n--- Example 15: Word Tokenization (NLTK) ---\")\n",
    "    text = \"Hello! How are you doing today? I'm doing great.\"\n",
    "    try:\n",
    "        result = TextCleaning(text).tokenize(method=\"word\")\n",
    "        print(f\"Result: {result}\")\n",
    "    except LookupError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Example 16: Sentence tokenization\n",
    "    print(\"\\n--- Example 16: Sentence Tokenization ---\")\n",
    "    text = \"Hello! How are you? I'm doing great. What about you?\"\n",
    "    try:\n",
    "        result = TextCleaning(text).tokenize(method=\"sentence\")\n",
    "        print(f\"Result: {result}\")\n",
    "    except LookupError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Example 17: Remove stopwords\n",
    "    print(\"\\n--- Example 17: Remove Stopwords (English) ---\")\n",
    "    text = \"This is a sample sentence with some common words\"\n",
    "    try:\n",
    "        result = TextCleaning(text).remove_stopwords(language=\"english\").get()\n",
    "        print(f\"Result: {result}\")\n",
    "    except LookupError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Example 18: Porter Stemming\n",
    "    print(\"\\n--- Example 18: Porter Stemming ---\")\n",
    "    text = \"running runs runner ran easily fairly\"\n",
    "    result = TextCleaning(text).stem(method=\"porter\").get()\n",
    "    print(f\"Result: {result}\")\n",
    "    \n",
    "    # Example 19: Snowball Stemming (supports multiple languages)\n",
    "    print(\"\\n--- Example 19: Snowball Stemming ---\")\n",
    "    text = \"running runs runner ran easily fairly\"\n",
    "    result = TextCleaning(text).stem(method=\"snowball\", language=\"english\").get()\n",
    "    print(f\"Result: {result}\")\n",
    "    \n",
    "    # Example 20: Lemmatization\n",
    "    print(\"\\n--- Example 20: Lemmatization (Noun) ---\")\n",
    "    text = \"running runs runner ran easily fairly\"\n",
    "    try:\n",
    "        result = TextCleaning(text).lemmatize(pos=\"n\").get()\n",
    "        print(f\"Result: {result}\")\n",
    "    except LookupError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Example 21: Lemmatization (Verb)\n",
    "    print(\"\\n--- Example 21: Lemmatization (Verb) ---\")\n",
    "    text = \"running runs runner ran\"\n",
    "    try:\n",
    "        result = TextCleaning(text).lemmatize(pos=\"v\").get()\n",
    "        print(f\"Result: {result}\")\n",
    "    except LookupError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    # Example 22: Complete pipeline with NLTK features\n",
    "    print(\"\\n--- Example 22: Complete NLP Pipeline ---\")\n",
    "    df_nlp = pd.DataFrame({\n",
    "        'text': [\n",
    "            \"I'm running quickly through the forest!\",\n",
    "            \"The cats were playing with their toys.\",\n",
    "            \"She doesn't like swimming in cold water.\"\n",
    "        ]\n",
    "    })\n",
    "    print(\"\\nOriginal DataFrame:\")\n",
    "    print(df_nlp)\n",
    "    \n",
    "    try:\n",
    "        df_nlp_cleaned = (TextCleaning(df_nlp, text_column='text')\n",
    "                         .lowercase()\n",
    "                         .expand_contractions()\n",
    "                         .remove_punctuation()\n",
    "                         .remove_stopwords(language=\"english\")\n",
    "                         .stem(method=\"porter\")\n",
    "                         .get())\n",
    "        print(\"\\nCleaned DataFrame (with stemming):\")\n",
    "        print(df_nlp_cleaned)\n",
    "    except LookupError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Please download NLTK data using: download_nltk_data()\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\nNLTK is not installed. Install it with: pip install nltk\")\n",
    "    print(\"Then run: download_nltk_data() to download required data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef4be1",
   "metadata": {},
   "source": [
    "## Part 4: Contractions Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "832b971b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total contractions available: 117\n",
      "\n",
      "Sample contractions:\n",
      "  ain't           -> am not\n",
      "  aren't          -> are not\n",
      "  can't           -> cannot\n",
      "  can't've        -> cannot have\n",
      "  'cause          -> because\n",
      "  could've        -> could have\n",
      "  couldn't        -> could not\n",
      "  couldn't've     -> could not have\n",
      "  didn't          -> did not\n",
      "  doesn't         -> does not\n",
      "\n",
      "--- Example 23: Custom Contractions ---\n",
      "Original: I'm gonna wanna do this\n",
      "Result: I am going to want to do this\n"
     ]
    }
   ],
   "source": [
    "contractions = get_contractions_dict()\n",
    "print(f\"\\nTotal contractions available: {len(contractions)}\")\n",
    "print(\"\\nSample contractions:\")\n",
    "sample_keys = list(contractions.keys())[:10]\n",
    "for key in sample_keys:\n",
    "    print(f\"  {key:15} -> {contractions[key]}\")\n",
    "\n",
    "# Example 23: Using custom contractions\n",
    "print(\"\\n--- Example 23: Custom Contractions ---\")\n",
    "custom_contractions = {\n",
    "    \"gonna\": \"going to\",\n",
    "    \"wanna\": \"want to\",\n",
    "    \"gotta\": \"got to\"\n",
    "}\n",
    "text = \"I'm gonna wanna do this\"\n",
    "result = TextCleaning(text).expand_contractions(custom_contractions=custom_contractions).get()\n",
    "print(f\"Original: {text}\")\n",
    "print(f\"Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f3a508",
   "metadata": {},
   "source": [
    "## Part 5 - Operation Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d046eda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example 24: Operation Log ---\n",
      "Result: hello world\n",
      "\n",
      "Operations performed:\n",
      "  1. lowercase: Converted text to lowercase\n",
      "  2. remove_punctuation: Removed punctuation (kept: 'none')\n",
      "  3. remove_whitespace: Removed whitespace using mode 'extra'\n"
     ]
    }
   ],
   "source": [
    "# Example 24: View operation log\n",
    "print(\"\\n--- Example 24: Operation Log ---\")\n",
    "cleaner = (TextCleaning(\"Hello World!\")\n",
    "           .lowercase()\n",
    "           .remove_punctuation()\n",
    "           .remove_whitespace(mode=\"extra\"))\n",
    "result = cleaner.get()\n",
    "log = cleaner.get_log()\n",
    "\n",
    "print(f\"Result: {result}\")\n",
    "print(\"\\nOperations performed:\")\n",
    "for i, op in enumerate(log, 1):\n",
    "    print(f\"  {i}. {op['operation']}: {op['details']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
